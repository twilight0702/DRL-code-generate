# 深度强化学习与代码生成实验计划

## 目标
- 设计一个极简的深度强化学习（DRL）实验，让智能体在小规模“代码生成/修复”任务上通过奖励信号学习输出可运行代码。
- 面向零基础：代码量和依赖尽量少，模型小且可在 CPU 上跑通。
- 产出物：可复现实验脚本、简短报告（方法、实验结果、误差分析）。

## 任务设定
- 输入：带占位符的简单函数描述（例如“实现绝对值 abs(x)”，“实现字符串反转”）。
- 动作/输出：智能体逐字符（或逐 token）生成 Python 代码，写入临时文件。
- 奖励：运行对应的单元测试，全部通过记为 +1，失败记为 0；可选奖励 shaping（如通过一半测试记 0.5）。
- 环境：自定义 Gym 风格环境，`step` 接收下一个 token，`done` 在生成结束符或长度上限时触发，`reset` 提供任务描述和初始空代码缓冲。

## 数据与基线
- 任务集合：手工编写 5–10 个极简函数（数学/字符串），确保测试覆盖边界情况。
- 训练/验证划分：8:2 划分任务；验证集仅用于评估。
- 基线：
  - `greedy-template`：用固定模板填入占位符（无学习）。
  - `random`：随机生成合法字符。
  - `supervised-warmup`（可选）：在小任务集上先做 teacher forcing，减少 RL 冷启动难度。

## 模型与算法
- 模型：轻量字符级 GRU/Transformer-Encoder-Decoder（隐藏维度小于 128，层数 1–2）。
- RL 算法：PPO（易实现且稳定），离散动作空间为字符表；为简化可用 Advantage Actor-Critic（A2C）。
- 技术细节：
  - 动作掩码：限制可用字符集（字母、数字、符号、换行、缩进），降低探索空间。
  - 截断：最大生成长度（如 200 字符）防止死循环。
  - 熵系数：鼓励早期探索。

## 实验流程
1) **环境搭建**：实现代码生成环境，支持任务列表、重置、步进、执行测试返回奖励。
2) **数据与测试**：编写每个任务的单元测试文件，确保独立可运行。
3) **基线跑通**：先跑 `greedy-template` 与 `random`，记录成功率。
4) **模型实现**：构建小型策略/价值网络，定义动作空间与文本编码。
5) **训练**：运行 PPO/A2C，观察成功率与平均奖励；可逐步增大任务数量。
6) **评估**：在验证任务上计算成功率、平均奖励、代码长度；展示样例生成代码。
7) **报告**：记录设置、结果表、失败案例与改进思路。

## 目录建议
- `env/`：自定义环境与任务定义。
- `tasks/`：任务描述与期望解答。
- `tests/`：单元测试集合。
- `models/`：策略/价值网络定义。
- `train.py`：训练入口。
- `eval.py`：评估脚本。
- `report.md`：实验报告。

## 资源与约束
- 计算：默认 CPU 训练，批次和模型极小；如时间紧张，可减少任务数或训练轮数。
- 依赖：仅用 PyTorch、gymnasium/自定义轻量环境、pytest（用于测试执行）。
- 随机性：设置随机种子，保证可重复性。

## 时间规划（示例）
- 第 1 天：明确任务列表，写好环境与测试；跑通基线。
- 第 2 天：实现模型与 PPO/A2C，完成最小可跑训练。
- 第 3 天：调小超参跑稳定曲线，整理结果与失败案例，完成报告初稿。

## 风险与应对
- 探索空间过大 → 收紧字符集/长度上限，增加模板初始化或监督预热。
- 奖励过稀疏 → 使用部分通过的比例奖励；或在语法检查通过时给小额奖励。
- 训练不收敛 → 降低模型容量与学习率，增大熵系数，增加训练步数。

---

• 搭建了最小骨架以便开工：新增任务集与环境、测试样例、随机 rollout 驱动及依赖清单。主要文件：requirements.txt，
  tasks/tasks.py（5 个示例任务+测试代码），env/code_env.py（字符级代码生成 Gym 环境，结束后跑 pytest 给奖励），tests/
  test_tasks.py（验收 canonical 解法），train.py（随机策略示例）。我尚未运行测试，请先安装依赖。

  下一步建议：

  1. 安装依赖并验收任务基线：pip install -r requirements.txt 后运行 pytest tests/test_tasks.py 确认 canonical 解法通过，
     再 python train.py --episodes 2 检查环境无报错。
     更新循环。
  4. 评估与报告：用 eval.py（待建）在验证任务上评估平均奖励/成功率，整理到 report.md。

---

